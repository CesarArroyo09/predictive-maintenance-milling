{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (\n",
    "    pd.read_csv('data/X_train_extended.csv'),\n",
    "    pd.read_csv('data/X_test_extended.csv'),\n",
    "    pd.read_csv('data/y_train.csv'),\n",
    "    pd.read_csv('data/y_test.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = (\n",
    "    X_train.drop(columns=['Type_L', 'Type_M']),\n",
    "    X_test.drop(columns=['Type_L', 'Type_M'])\n",
    ")\n",
    "\n",
    "y_train, y_test = y_train['Failure type'], y_test['Failure type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 14:31:09.625166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 14:31:09.625774: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 14:31:09.628626: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 14:31:09.636438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 14:31:09.650062: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 14:31:09.653555: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 14:31:09.663807: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 14:31:10.530543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722025871.352170  401422 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-26 14:31:11.352499: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(7,)),  # 7 input features\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')  # 7 classes for the output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['recall', 'f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, tf.keras.models.Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools import results\n",
    "from mltools import models as models_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wrapper = models_tools.NeuralNetworkWrapper(model=model, name='neural_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Type of y_train_encoded: <class 'numpy.ndarray'>\n",
      "Shape of y_train_encoded: (8000, 7)\n",
      "Type of X_train: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X_train: (8000, 7)\n",
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - f1_score: 0.0223 - loss: 2.1110 - recall: 3.8698e-04 - val_f1_score: 0.1029 - val_loss: 1.8190 - val_recall: 0.0044\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.1254 - loss: 1.3209 - recall: 0.0173 - val_f1_score: 0.1587 - val_loss: 1.4911 - val_recall: 0.1381\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.1820 - loss: 1.2337 - recall: 0.1832 - val_f1_score: 0.1816 - val_loss: 1.3453 - val_recall: 0.2450\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2062 - loss: 0.9352 - recall: 0.2479 - val_f1_score: 0.1907 - val_loss: 1.2671 - val_recall: 0.3262\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2054 - loss: 0.8102 - recall: 0.3408 - val_f1_score: 0.2177 - val_loss: 1.1241 - val_recall: 0.3862\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2285 - loss: 0.8245 - recall: 0.3934 - val_f1_score: 0.2009 - val_loss: 1.2405 - val_recall: 0.3344\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2129 - loss: 0.7371 - recall: 0.3364 - val_f1_score: 0.2439 - val_loss: 1.0582 - val_recall: 0.4031\n",
      "Epoch 8/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2411 - loss: 0.7585 - recall: 0.3765 - val_f1_score: 0.2214 - val_loss: 1.1078 - val_recall: 0.4650\n",
      "Epoch 9/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2527 - loss: 0.7298 - recall: 0.4798 - val_f1_score: 0.2045 - val_loss: 1.0940 - val_recall: 0.4219\n",
      "Epoch 10/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2412 - loss: 0.5524 - recall: 0.4970 - val_f1_score: 0.2136 - val_loss: 1.1307 - val_recall: 0.4363\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2542 - loss: 0.6187 - recall: 0.4528 - val_f1_score: 0.2199 - val_loss: 1.2752 - val_recall: 0.3887\n",
      "Epoch 12/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2588 - loss: 0.5739 - recall: 0.4446 - val_f1_score: 0.2655 - val_loss: 0.9771 - val_recall: 0.5200\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2742 - loss: 0.4482 - recall: 0.5290 - val_f1_score: 0.2610 - val_loss: 0.9526 - val_recall: 0.5169\n",
      "Epoch 14/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2939 - loss: 0.5073 - recall: 0.5220 - val_f1_score: 0.2291 - val_loss: 1.1708 - val_recall: 0.4212\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2752 - loss: 0.5460 - recall: 0.4562 - val_f1_score: 0.2782 - val_loss: 1.0169 - val_recall: 0.5063\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2676 - loss: 0.5346 - recall: 0.5470 - val_f1_score: 0.2472 - val_loss: 0.9506 - val_recall: 0.5713\n",
      "Epoch 17/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2976 - loss: 0.4772 - recall: 0.6078 - val_f1_score: 0.2638 - val_loss: 1.2091 - val_recall: 0.4400\n",
      "Epoch 18/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2839 - loss: 0.4649 - recall: 0.5383 - val_f1_score: 0.2764 - val_loss: 0.9395 - val_recall: 0.5638\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3008 - loss: 0.4177 - recall: 0.5831 - val_f1_score: 0.3211 - val_loss: 0.8871 - val_recall: 0.5512\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2983 - loss: 0.4577 - recall: 0.5712 - val_f1_score: 0.2849 - val_loss: 0.9916 - val_recall: 0.5806\n",
      "neural_network model fitted.\n"
     ]
    }
   ],
   "source": [
    "nn_wrapper.fit(X_train, y_train, sampling_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = results.ExperimentAutomation([nn_wrapper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (8000,) in experiments\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Type of y_train_encoded: <class 'numpy.ndarray'>\n",
      "Shape of y_train_encoded: (8000, 7)\n",
      "Type of X_train: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X_train: (8000, 7)\n",
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3432 - loss: 0.4472 - recall: 0.6014 - val_f1_score: 0.3203 - val_loss: 0.7162 - val_recall: 0.6625\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3307 - loss: 0.4662 - recall: 0.6449 - val_f1_score: 0.3194 - val_loss: 0.9226 - val_recall: 0.5919\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3521 - loss: 0.3896 - recall: 0.6275 - val_f1_score: 0.3039 - val_loss: 1.0045 - val_recall: 0.5387\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3302 - loss: 0.4191 - recall: 0.5855 - val_f1_score: 0.2947 - val_loss: 0.7837 - val_recall: 0.6450\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3462 - loss: 0.4163 - recall: 0.6235 - val_f1_score: 0.3538 - val_loss: 0.6224 - val_recall: 0.6994\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3566 - loss: 0.3611 - recall: 0.6922 - val_f1_score: 0.2679 - val_loss: 0.8178 - val_recall: 0.6375\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3106 - loss: 0.3435 - recall: 0.6435 - val_f1_score: 0.3283 - val_loss: 0.7480 - val_recall: 0.6525\n",
      "Epoch 8/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.3336 - loss: 0.3619 - recall: 0.6613 - val_f1_score: 0.3587 - val_loss: 0.9149 - val_recall: 0.5938\n",
      "Epoch 9/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3765 - loss: 0.3474 - recall: 0.6425 - val_f1_score: 0.3039 - val_loss: 0.7932 - val_recall: 0.6481\n",
      "Epoch 10/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3455 - loss: 0.3078 - recall: 0.6855 - val_f1_score: 0.3744 - val_loss: 0.6039 - val_recall: 0.7094\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3600 - loss: 0.3301 - recall: 0.6809 - val_f1_score: 0.3218 - val_loss: 0.7765 - val_recall: 0.6600\n",
      "Epoch 12/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3459 - loss: 0.3966 - recall: 0.6606 - val_f1_score: 0.3658 - val_loss: 0.7719 - val_recall: 0.6575\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.4110 - loss: 0.3072 - recall: 0.6789 - val_f1_score: 0.3688 - val_loss: 0.6876 - val_recall: 0.6687\n",
      "Epoch 14/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3843 - loss: 0.3138 - recall: 0.6818 - val_f1_score: 0.3658 - val_loss: 0.6175 - val_recall: 0.7419\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3901 - loss: 0.2946 - recall: 0.6930 - val_f1_score: 0.3762 - val_loss: 0.7742 - val_recall: 0.6481\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3762 - loss: 0.2792 - recall: 0.6828 - val_f1_score: 0.3606 - val_loss: 0.7838 - val_recall: 0.6725\n",
      "Epoch 17/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.4009 - loss: 0.2506 - recall: 0.7133 - val_f1_score: 0.4040 - val_loss: 0.6671 - val_recall: 0.6969\n",
      "Epoch 18/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3921 - loss: 0.3045 - recall: 0.7117 - val_f1_score: 0.4149 - val_loss: 0.7082 - val_recall: 0.6794\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.4254 - loss: 0.2301 - recall: 0.7139 - val_f1_score: 0.3478 - val_loss: 0.7660 - val_recall: 0.6625\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3840 - loss: 0.2251 - recall: 0.7018 - val_f1_score: 0.3490 - val_loss: 0.7437 - val_recall: 0.6631\n",
      "neural_network model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Results recorded for neural_network with no sampling.\n",
      "Shape of y_train: (8000,) in experiments\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Resampling the training data using oversampling.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (54054,)\n",
      "Type of y_train_encoded: <class 'numpy.ndarray'>\n",
      "Shape of y_train_encoded: (54054, 7)\n",
      "Type of X_train: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X_train: (54054, 7)\n",
      "Epoch 1/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.8351 - loss: 0.1916 - recall: 0.9409 - val_f1_score: 0.1579 - val_loss: 2.0198 - val_recall: 0.2874\n",
      "Epoch 2/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8546 - loss: 0.1322 - recall: 0.9669 - val_f1_score: 0.1579 - val_loss: 2.7538 - val_recall: 0.2874\n",
      "Epoch 3/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8341 - loss: 0.1058 - recall: 0.9727 - val_f1_score: 0.1579 - val_loss: 2.7139 - val_recall: 0.3271\n",
      "Epoch 4/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8505 - loss: 0.0908 - recall: 0.9766 - val_f1_score: 0.1579 - val_loss: 3.4374 - val_recall: 0.2874\n",
      "Epoch 5/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8466 - loss: 0.0780 - recall: 0.9804 - val_f1_score: 0.1579 - val_loss: 2.7501 - val_recall: 0.3271\n",
      "Epoch 6/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8563 - loss: 0.0696 - recall: 0.9823 - val_f1_score: 0.1579 - val_loss: 3.0296 - val_recall: 0.3271\n",
      "Epoch 7/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8586 - loss: 0.0611 - recall: 0.9843 - val_f1_score: 0.1841 - val_loss: 2.1315 - val_recall: 0.3659\n",
      "Epoch 8/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9030 - loss: 0.0583 - recall: 0.9857 - val_f1_score: 0.1712 - val_loss: 2.4816 - val_recall: 0.3659\n",
      "Epoch 9/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8702 - loss: 0.0517 - recall: 0.9870 - val_f1_score: 0.1712 - val_loss: 2.4499 - val_recall: 0.3659\n",
      "Epoch 10/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8900 - loss: 0.0452 - recall: 0.9892 - val_f1_score: 0.1841 - val_loss: 2.5215 - val_recall: 0.4075\n",
      "Epoch 11/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8959 - loss: 0.0425 - recall: 0.9897 - val_f1_score: 0.2057 - val_loss: 2.1178 - val_recall: 0.4469\n",
      "Epoch 12/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.8544 - loss: 0.0436 - recall: 0.9892 - val_f1_score: 0.2233 - val_loss: 2.1487 - val_recall: 0.5668\n",
      "Epoch 13/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9256 - loss: 0.0374 - recall: 0.9907 - val_f1_score: 0.2386 - val_loss: 1.3979 - val_recall: 0.6465\n",
      "Epoch 14/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9235 - loss: 0.0363 - recall: 0.9908 - val_f1_score: 0.2314 - val_loss: 1.4546 - val_recall: 0.6074\n",
      "Epoch 15/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9031 - loss: 0.0352 - recall: 0.9911 - val_f1_score: 0.2145 - val_loss: 2.2145 - val_recall: 0.5259\n",
      "Epoch 16/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9267 - loss: 0.0321 - recall: 0.9921 - val_f1_score: 0.2311 - val_loss: 2.0119 - val_recall: 0.5668\n",
      "Epoch 17/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9129 - loss: 0.0321 - recall: 0.9924 - val_f1_score: 0.2386 - val_loss: 1.4596 - val_recall: 0.6465\n",
      "Epoch 18/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9368 - loss: 0.0324 - recall: 0.9919 - val_f1_score: 0.2451 - val_loss: 1.7117 - val_recall: 0.6845\n",
      "Epoch 19/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9110 - loss: 0.0309 - recall: 0.9927 - val_f1_score: 0.2453 - val_loss: 1.3003 - val_recall: 0.6860\n",
      "Epoch 20/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9493 - loss: 0.0292 - recall: 0.9930 - val_f1_score: 0.2311 - val_loss: 1.5594 - val_recall: 0.6059\n",
      "neural_network_oversampling model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step\n",
      "Results recorded for neural_network_oversampling with oversampling.\n",
      "Shape of y_train: (8000,) in experiments\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Resampling the training data using undersampling.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (105,)\n",
      "Type of y_train_encoded: <class 'numpy.ndarray'>\n",
      "Shape of y_train_encoded: (105, 7)\n",
      "Type of X_train: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X_train: (105, 7)\n",
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - f1_score: 0.8379 - loss: 0.0328 - recall: 0.9764 - val_f1_score: 0.2422 - val_loss: 1.4758 - val_recall: 0.6667\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0186 - recall: 1.0000 - val_f1_score: 0.2422 - val_loss: 1.4629 - val_recall: 0.6667\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0243 - recall: 1.0000 - val_f1_score: 0.2422 - val_loss: 1.4591 - val_recall: 0.6667\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0200 - recall: 1.0000 - val_f1_score: 0.2422 - val_loss: 1.4360 - val_recall: 0.6667\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8571 - loss: 0.0152 - recall: 1.0000 - val_f1_score: 0.2422 - val_loss: 1.4069 - val_recall: 0.6667\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0120 - recall: 1.0000 - val_f1_score: 0.2422 - val_loss: 1.3760 - val_recall: 0.6667\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0095 - recall: 1.0000 - val_f1_score: 0.2500 - val_loss: 1.3501 - val_recall: 0.7143\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0059 - recall: 1.0000 - val_f1_score: 0.2500 - val_loss: 1.3324 - val_recall: 0.7143\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8571 - loss: 0.0080 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3227 - val_recall: 0.7619\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8571 - loss: 0.0050 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3162 - val_recall: 0.7619\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0049 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3180 - val_recall: 0.7619\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.8571 - loss: 0.0051 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3234 - val_recall: 0.7619\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0049 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3278 - val_recall: 0.7619\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0057 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3297 - val_recall: 0.7619\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - f1_score: 0.8571 - loss: 0.0038 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3295 - val_recall: 0.7619\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - f1_score: 0.8571 - loss: 0.0041 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3277 - val_recall: 0.7619\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0044 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3247 - val_recall: 0.7619\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - f1_score: 0.8571 - loss: 0.0042 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3221 - val_recall: 0.7619\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0034 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3201 - val_recall: 0.7619\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - f1_score: 0.8571 - loss: 0.0039 - recall: 1.0000 - val_f1_score: 0.2571 - val_loss: 1.3211 - val_recall: 0.7619\n",
      "neural_network_undersampling model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step\n",
      "Results recorded for neural_network_undersampling with undersampling.\n",
      "Shape of y_train: (8000,) in experiments\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Resampling the training data using smote.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (54054,)\n",
      "Type of y_train_encoded: <class 'numpy.ndarray'>\n",
      "Shape of y_train_encoded: (54054, 7)\n",
      "Type of X_train: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X_train: (54054, 7)\n",
      "Epoch 1/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9210 - loss: 0.0798 - recall: 0.9776 - val_f1_score: 0.2573 - val_loss: 0.8776 - val_recall: 0.7650\n",
      "Epoch 2/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9524 - loss: 0.0487 - recall: 0.9851 - val_f1_score: 0.2572 - val_loss: 0.7740 - val_recall: 0.7672\n",
      "Epoch 3/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9382 - loss: 0.0452 - recall: 0.9865 - val_f1_score: 0.2668 - val_loss: 0.4674 - val_recall: 0.8344\n",
      "Epoch 4/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9576 - loss: 0.0443 - recall: 0.9882 - val_f1_score: 0.2569 - val_loss: 0.7280 - val_recall: 0.7602\n",
      "Epoch 5/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9642 - loss: 0.0417 - recall: 0.9885 - val_f1_score: 0.2584 - val_loss: 0.6953 - val_recall: 0.7740\n",
      "Epoch 6/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9376 - loss: 0.0411 - recall: 0.9882 - val_f1_score: 0.2161 - val_loss: 1.3606 - val_recall: 0.5296\n",
      "Epoch 7/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9487 - loss: 0.0392 - recall: 0.9896 - val_f1_score: 0.2624 - val_loss: 0.5619 - val_recall: 0.7984\n",
      "Epoch 8/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9444 - loss: 0.0386 - recall: 0.9888 - val_f1_score: 0.2617 - val_loss: 0.5728 - val_recall: 0.7901\n",
      "Epoch 9/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9680 - loss: 0.0333 - recall: 0.9914 - val_f1_score: 0.2575 - val_loss: 0.6869 - val_recall: 0.7598\n",
      "Epoch 10/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9350 - loss: 0.0361 - recall: 0.9902 - val_f1_score: 0.2504 - val_loss: 0.8969 - val_recall: 0.7057\n",
      "Epoch 11/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9393 - loss: 0.0358 - recall: 0.9908 - val_f1_score: 0.2696 - val_loss: 0.4957 - val_recall: 0.8551\n",
      "Epoch 12/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9582 - loss: 0.0337 - recall: 0.9914 - val_f1_score: 0.2525 - val_loss: 0.9996 - val_recall: 0.7261\n",
      "Epoch 13/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9634 - loss: 0.0368 - recall: 0.9907 - val_f1_score: 0.2715 - val_loss: 0.4384 - val_recall: 0.8687\n",
      "Epoch 14/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9520 - loss: 0.0318 - recall: 0.9915 - val_f1_score: 0.2698 - val_loss: 0.5029 - val_recall: 0.8561\n",
      "Epoch 15/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9086 - loss: 0.0320 - recall: 0.9919 - val_f1_score: 0.2692 - val_loss: 0.5557 - val_recall: 0.8503\n",
      "Epoch 16/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9532 - loss: 0.0309 - recall: 0.9920 - val_f1_score: 0.2784 - val_loss: 0.2495 - val_recall: 0.9307\n",
      "Epoch 17/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9155 - loss: 0.0301 - recall: 0.9921 - val_f1_score: 0.2805 - val_loss: 0.2155 - val_recall: 0.9498\n",
      "Epoch 18/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9588 - loss: 0.0293 - recall: 0.9926 - val_f1_score: 0.2762 - val_loss: 0.3388 - val_recall: 0.9111\n",
      "Epoch 19/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9805 - loss: 0.0289 - recall: 0.9935 - val_f1_score: 0.2781 - val_loss: 0.2930 - val_recall: 0.9271\n",
      "Epoch 20/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9622 - loss: 0.0288 - recall: 0.9918 - val_f1_score: 0.2751 - val_loss: 0.4572 - val_recall: 0.8944\n",
      "neural_network_smote model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Results recorded for neural_network_smote with smote.\n"
     ]
    }
   ],
   "source": [
    "experiment.run_experiment(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(experiment.results.results_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1930.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.43</td>\n",
       "      <td>21.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.34</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.42</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>5.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1930.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>21.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1930.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.24</td>\n",
       "      <td>9.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>21.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.75</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1930.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.24</td>\n",
       "      <td>9.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>21.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.77</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>16.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support  \\\n",
       "0                  1.00    0.66      0.80  1930.00   \n",
       "1                  0.06    0.89      0.11     9.00   \n",
       "2                  0.28    0.90      0.43    21.00   \n",
       "3                  0.25    1.00      0.40    16.00   \n",
       "4                  0.22    0.81      0.34    16.00   \n",
       "5                  0.00    0.00      0.00     3.00   \n",
       "6                  0.42    1.00      0.59     5.00   \n",
       "accuracy           0.67    0.67      0.67     0.67   \n",
       "macro avg          0.32    0.75      0.38  2000.00   \n",
       "weighted avg       0.97    0.67      0.78  2000.00   \n",
       "0                  0.99    0.98      0.98  1930.00   \n",
       "1                  0.21    0.67      0.32     9.00   \n",
       "2                  0.79    0.90      0.84    21.00   \n",
       "3                  0.67    0.88      0.76    16.00   \n",
       "4                  0.68    0.81      0.74    16.00   \n",
       "5                  0.00    0.00      0.00     3.00   \n",
       "6                  1.00    0.80      0.89     5.00   \n",
       "accuracy           0.97    0.97      0.97     0.97   \n",
       "macro avg          0.62    0.72      0.65  2000.00   \n",
       "weighted avg       0.98    0.97      0.97  2000.00   \n",
       "0                  1.00    0.96      0.98  1930.00   \n",
       "1                  0.14    0.67      0.24     9.00   \n",
       "2                  0.66    0.90      0.76    21.00   \n",
       "3                  0.62    0.94      0.75    16.00   \n",
       "4                  0.47    1.00      0.64    16.00   \n",
       "5                  0.00    0.00      0.00     3.00   \n",
       "6                  0.80    0.80      0.80     5.00   \n",
       "accuracy           0.95    0.95      0.95     0.95   \n",
       "macro avg          0.53    0.75      0.59  2000.00   \n",
       "weighted avg       0.98    0.95      0.96  2000.00   \n",
       "0                  0.99    0.96      0.97  1930.00   \n",
       "1                  0.14    0.67      0.24     9.00   \n",
       "2                  0.78    0.86      0.82    21.00   \n",
       "3                  0.65    0.94      0.77    16.00   \n",
       "4                  0.68    0.81      0.74    16.00   \n",
       "5                  0.00    0.00      0.00     3.00   \n",
       "6                  1.00    0.80      0.89     5.00   \n",
       "accuracy           0.95    0.95      0.95     0.95   \n",
       "macro avg          0.61    0.72      0.63  2000.00   \n",
       "weighted avg       0.98    0.95      0.96  2000.00   \n",
       "\n",
       "                                     model  \n",
       "0                           neural_network  \n",
       "1                           neural_network  \n",
       "2                           neural_network  \n",
       "3                           neural_network  \n",
       "4                           neural_network  \n",
       "5                           neural_network  \n",
       "6                           neural_network  \n",
       "accuracy                    neural_network  \n",
       "macro avg                   neural_network  \n",
       "weighted avg                neural_network  \n",
       "0              neural_network_oversampling  \n",
       "1              neural_network_oversampling  \n",
       "2              neural_network_oversampling  \n",
       "3              neural_network_oversampling  \n",
       "4              neural_network_oversampling  \n",
       "5              neural_network_oversampling  \n",
       "6              neural_network_oversampling  \n",
       "accuracy       neural_network_oversampling  \n",
       "macro avg      neural_network_oversampling  \n",
       "weighted avg   neural_network_oversampling  \n",
       "0             neural_network_undersampling  \n",
       "1             neural_network_undersampling  \n",
       "2             neural_network_undersampling  \n",
       "3             neural_network_undersampling  \n",
       "4             neural_network_undersampling  \n",
       "5             neural_network_undersampling  \n",
       "6             neural_network_undersampling  \n",
       "accuracy      neural_network_undersampling  \n",
       "macro avg     neural_network_undersampling  \n",
       "weighted avg  neural_network_undersampling  \n",
       "0                     neural_network_smote  \n",
       "1                     neural_network_smote  \n",
       "2                     neural_network_smote  \n",
       "3                     neural_network_smote  \n",
       "4                     neural_network_smote  \n",
       "5                     neural_network_smote  \n",
       "6                     neural_network_smote  \n",
       "accuracy              neural_network_smote  \n",
       "macro avg             neural_network_smote  \n",
       "weighted avg          neural_network_smote  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(experiment.results.results_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
