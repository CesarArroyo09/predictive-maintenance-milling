{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (\n",
    "    pd.read_csv('data/X_train_extended.csv'),\n",
    "    pd.read_csv('data/X_test_extended.csv'),\n",
    "    pd.read_csv('data/y_train.csv'),\n",
    "    pd.read_csv('data/y_test.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = (\n",
    "    X_train.drop(columns=['Type_L', 'Type_M']),\n",
    "    X_test.drop(columns=['Type_L', 'Type_M'])\n",
    ")\n",
    "\n",
    "y_train, y_test = y_train['Failure type'], y_test['Failure type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una red neuronal, las variables objetivos las codificaremoss usando one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 16:18:03.476725: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 16:18:03.477608: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 16:18:03.482228: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 16:18:03.492907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 16:18:03.510141: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 16:18:03.516396: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 16:18:03.528838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 16:18:04.775101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos pesos para tener en cuenta el desbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train.values.flatten()\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722032311.506935  425983 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-26 16:18:31.509617: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(7,)),  # 7 input features\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')  # 7 classes for the output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['recall', 'f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, tf.keras.models.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - f1_score: 0.0389 - loss: 2.0746 - recall: 8.2227e-04 - val_f1_score: 0.1473 - val_loss: 1.6601 - val_recall: 0.0012\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.1611 - loss: 1.4330 - recall: 0.0228 - val_f1_score: 0.1793 - val_loss: 1.4137 - val_recall: 0.1231\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.1727 - loss: 1.1116 - recall: 0.1675 - val_f1_score: 0.1683 - val_loss: 1.3278 - val_recall: 0.2463\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.1846 - loss: 0.8842 - recall: 0.2983 - val_f1_score: 0.2038 - val_loss: 1.2350 - val_recall: 0.3050\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2080 - loss: 0.8941 - recall: 0.3361 - val_f1_score: 0.1966 - val_loss: 1.1808 - val_recall: 0.3500\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2184 - loss: 0.7844 - recall: 0.3763 - val_f1_score: 0.2327 - val_loss: 1.1843 - val_recall: 0.3444\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2372 - loss: 0.6960 - recall: 0.3925 - val_f1_score: 0.2701 - val_loss: 1.1143 - val_recall: 0.3663\n",
      "Epoch 8/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2520 - loss: 0.7215 - recall: 0.3810 - val_f1_score: 0.1972 - val_loss: 1.1326 - val_recall: 0.3856\n",
      "Epoch 9/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2270 - loss: 0.6541 - recall: 0.4326 - val_f1_score: 0.2488 - val_loss: 1.1039 - val_recall: 0.3906\n",
      "Epoch 10/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2416 - loss: 0.5766 - recall: 0.4117 - val_f1_score: 0.2527 - val_loss: 1.0852 - val_recall: 0.4087\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2568 - loss: 0.6598 - recall: 0.4415 - val_f1_score: 0.2280 - val_loss: 1.0375 - val_recall: 0.4394\n",
      "Epoch 12/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2488 - loss: 0.6025 - recall: 0.4438 - val_f1_score: 0.2284 - val_loss: 1.1926 - val_recall: 0.3994\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2737 - loss: 0.6244 - recall: 0.4294 - val_f1_score: 0.2442 - val_loss: 1.1211 - val_recall: 0.4250\n",
      "Epoch 14/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2509 - loss: 0.6190 - recall: 0.3967 - val_f1_score: 0.2672 - val_loss: 1.1102 - val_recall: 0.4431\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3030 - loss: 0.5797 - recall: 0.4800 - val_f1_score: 0.2737 - val_loss: 1.0787 - val_recall: 0.4300\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3057 - loss: 0.4863 - recall: 0.5029 - val_f1_score: 0.2361 - val_loss: 1.0798 - val_recall: 0.4531\n",
      "Epoch 17/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2984 - loss: 0.5080 - recall: 0.4767 - val_f1_score: 0.3242 - val_loss: 1.0372 - val_recall: 0.4325\n",
      "Epoch 18/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3440 - loss: 0.4517 - recall: 0.5153 - val_f1_score: 0.2928 - val_loss: 0.9589 - val_recall: 0.4756\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.2819 - loss: 0.5010 - recall: 0.4902 - val_f1_score: 0.3509 - val_loss: 0.7740 - val_recall: 0.5944\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3475 - loss: 0.4270 - recall: 0.5729 - val_f1_score: 0.2784 - val_loss: 0.8688 - val_recall: 0.5931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f22b5592210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train.values,\n",
    "    y_train_encoded,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3144 - loss: 0.8612 - recall: 0.5914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8564415574073792,\n",
       " 0.5950000286102295,\n",
       " <tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
       " array([0.7721639 , 0.06666666, 0.29921257, 0.47619042, 0.25742573,\n",
       "        0.00677966, 0.37037033], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss = model.evaluate(X_test, y_test_encoded)\n",
    "# print(f'Test accuracy: {accuracy}')\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in y_pred, get the index of the highest value\n",
    "y_pred_argmax = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_argmax[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test.values, y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77      1930\n",
      "           1       0.03      0.89      0.07         9\n",
      "           2       0.18      0.90      0.30        21\n",
      "           3       0.32      0.94      0.48        16\n",
      "           4       0.15      0.81      0.26        16\n",
      "           5       0.00      0.33      0.01         3\n",
      "           6       0.23      1.00      0.37         5\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.27      0.79      0.32      2000\n",
      "weighted avg       0.97      0.64      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos el `NeuralNetworkWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltools import results\n",
    "from mltools import models as models_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wrapper = models_tools.NeuralNetworkWrapper(model=model, name='neural_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3289 - loss: 0.4364 - recall: 0.6239 - val_f1_score: 0.2586 - val_loss: 0.9363 - val_recall: 0.5606\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.3005 - loss: 0.5159 - recall: 0.5540 - val_f1_score: 0.2974 - val_loss: 0.9450 - val_recall: 0.5437\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3345 - loss: 0.4017 - recall: 0.5942 - val_f1_score: 0.3273 - val_loss: 0.9483 - val_recall: 0.5500\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3254 - loss: 0.4040 - recall: 0.5788 - val_f1_score: 0.3412 - val_loss: 0.8214 - val_recall: 0.5894\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.3364 - loss: 0.3849 - recall: 0.5891 - val_f1_score: 0.2871 - val_loss: 0.8371 - val_recall: 0.6256\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3269 - loss: 0.3625 - recall: 0.6105 - val_f1_score: 0.3843 - val_loss: 0.9015 - val_recall: 0.5813\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3839 - loss: 0.3370 - recall: 0.6179 - val_f1_score: 0.3321 - val_loss: 0.9363 - val_recall: 0.5675\n",
      "Epoch 8/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3594 - loss: 0.3391 - recall: 0.6071 - val_f1_score: 0.3921 - val_loss: 0.8083 - val_recall: 0.6150\n",
      "Epoch 9/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.3587 - loss: 0.3210 - recall: 0.6068 - val_f1_score: 0.3242 - val_loss: 0.7310 - val_recall: 0.6731\n",
      "Epoch 10/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3415 - loss: 0.3817 - recall: 0.6497 - val_f1_score: 0.3730 - val_loss: 0.6930 - val_recall: 0.6975\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3975 - loss: 0.3769 - recall: 0.6479 - val_f1_score: 0.3694 - val_loss: 0.7554 - val_recall: 0.6413\n",
      "Epoch 12/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3700 - loss: 0.3024 - recall: 0.6576 - val_f1_score: 0.4193 - val_loss: 0.7256 - val_recall: 0.6544\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.4310 - loss: 0.3526 - recall: 0.6580 - val_f1_score: 0.3819 - val_loss: 0.7621 - val_recall: 0.6719\n",
      "Epoch 14/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.3992 - loss: 0.2957 - recall: 0.6525 - val_f1_score: 0.4280 - val_loss: 0.7034 - val_recall: 0.6769\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.3540 - loss: 0.3163 - recall: 0.6845 - val_f1_score: 0.3450 - val_loss: 0.9378 - val_recall: 0.5962\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - f1_score: 0.3975 - loss: 0.2949 - recall: 0.6344 - val_f1_score: 0.4189 - val_loss: 0.7166 - val_recall: 0.6844\n",
      "Epoch 17/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - f1_score: 0.3912 - loss: 0.3107 - recall: 0.6661 - val_f1_score: 0.4080 - val_loss: 0.6607 - val_recall: 0.7069\n",
      "Epoch 18/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.4079 - loss: 0.2743 - recall: 0.6908 - val_f1_score: 0.3832 - val_loss: 0.5769 - val_recall: 0.7444\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - f1_score: 0.3673 - loss: 0.2642 - recall: 0.7410 - val_f1_score: 0.3584 - val_loss: 0.7466 - val_recall: 0.6650\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.3902 - loss: 0.2487 - recall: 0.6965 - val_f1_score: 0.4262 - val_loss: 0.8006 - val_recall: 0.6338\n",
      "neural_network model fitted.\n"
     ]
    }
   ],
   "source": [
    "nn_wrapper.fit(X_train, y_train, sampling_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy for neural_network: 0.6465\n",
      "Classification Report for neural_network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78      1930\n",
      "           1       0.06      0.89      0.11         9\n",
      "           2       0.28      0.90      0.43        21\n",
      "           3       0.39      0.94      0.56        16\n",
      "           4       0.19      0.88      0.31        16\n",
      "           5       0.00      0.33      0.00         3\n",
      "           6       0.62      1.00      0.77         5\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.36      0.80      0.42      2000\n",
      "weighted avg       0.97      0.65      0.77      2000\n",
      "\n",
      "\n",
      "Confusion Matrix for neural_network:\n",
      "[[1231  126   48   23   59  441    2]\n",
      " [   0    8    0    0    1    0    0]\n",
      " [   0    2   19    0    0    0    0]\n",
      " [   0    0    0   15    0    1    0]\n",
      " [   0    1    0    0   14    0    1]\n",
      " [   2    0    0    0    0    1    0]\n",
      " [   0    0    0    0    0    0    5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6465,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       1.00      0.64      0.78      1930\\n           1       0.06      0.89      0.11         9\\n           2       0.28      0.90      0.43        21\\n           3       0.39      0.94      0.56        16\\n           4       0.19      0.88      0.31        16\\n           5       0.00      0.33      0.00         3\\n           6       0.62      1.00      0.77         5\\n\\n    accuracy                           0.65      2000\\n   macro avg       0.36      0.80      0.42      2000\\nweighted avg       0.97      0.65      0.77      2000\\n')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_wrapper.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
