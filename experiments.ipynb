{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución de modelos\n",
    "\n",
    "Para esto hemos creado el módulo `mltools.results` el cual contiene dos clases:\n",
    "1. `ExperimentResults`: La cual tiene la habilidad de ir guardando los resultados de los experimentos realizados.\n",
    "2. `ExperimentAutomation`: La cual tiene la habilidad de automatizar la ejecución de los experimentos e ir guardando los resultados en una instancia de `ExperimentResults`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 16:56:30.434502: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 16:56:30.442293: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 16:56:30.486049: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-26 16:56:30.532282: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 16:56:30.571700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 16:56:30.584021: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 16:56:30.646338: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 16:56:32.480657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from mltools import models, results\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models as tf_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "\n",
    "Usamos los datos extendidos y descartamos las variables categóricas. Para el objetivo usamos la variable `Failure type` para clasificar el tipo de falla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets_paths(suffix: str = None):\n",
    "    data_dir = 'data'\n",
    "    datasets = [\"X_train_extended\", \"X_test_extended\", \"y_train\", \"y_test\"]\n",
    "    if suffix:\n",
    "        datasets = [os.path.join(data_dir, f\"{dataset}_{suffix}.csv\") for dataset in datasets]\n",
    "    else:\n",
    "        datasets = [os.path.join(data_dir, f\"{dataset}.csv\") for dataset in datasets]\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(suffix: str = None):\n",
    "    datasets = generate_datasets_paths(suffix)\n",
    "    X_train = pd.read_csv(datasets[0])\n",
    "    X_test = pd.read_csv(datasets[1])\n",
    "    y_train = pd.read_csv(datasets[2])\n",
    "    y_test = pd.read_csv(datasets[3])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitamos las columnas que vienen del one-hot encoding de la variable categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['Type_L', 'Type_M'])\n",
    "X_test = X_test.drop(columns=['Type_L', 'Type_M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo queremos predecir en `Failure type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['Failure type']\n",
    "y_test = y_test['Failure type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Temperature difference [K]</th>\n",
       "      <th>Rotational power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.354642</td>\n",
       "      <td>-1.014674</td>\n",
       "      <td>-0.239039</td>\n",
       "      <td>-0.059097</td>\n",
       "      <td>-0.440162</td>\n",
       "      <td>-0.792467</td>\n",
       "      <td>-0.100567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.651210</td>\n",
       "      <td>-1.486322</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>-0.539312</td>\n",
       "      <td>2.045097</td>\n",
       "      <td>1.102016</td>\n",
       "      <td>-0.295095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002926</td>\n",
       "      <td>-1.284187</td>\n",
       "      <td>-1.110534</td>\n",
       "      <td>1.161451</td>\n",
       "      <td>1.400188</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.891225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.753586</td>\n",
       "      <td>0.063378</td>\n",
       "      <td>1.498401</td>\n",
       "      <td>-1.109568</td>\n",
       "      <td>-1.383932</td>\n",
       "      <td>1.600564</td>\n",
       "      <td>-0.751564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094169</td>\n",
       "      <td>0.400269</td>\n",
       "      <td>-0.599849</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.078911</td>\n",
       "      <td>0.404048</td>\n",
       "      <td>0.054690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0            -0.354642                -1.014674               -0.239039   \n",
       "1            -1.651210                -1.486322                0.593600   \n",
       "2            -1.002926                -1.284187               -1.110534   \n",
       "3            -0.753586                 0.063378                1.498401   \n",
       "4             0.094169                 0.400269               -0.599849   \n",
       "\n",
       "   Torque [Nm]  Tool wear [min]  Temperature difference [K]  Rotational power  \n",
       "0    -0.059097        -0.440162                   -0.792467         -0.100567  \n",
       "1    -0.539312         2.045097                    1.102016         -0.295095  \n",
       "2     1.161451         1.400188                    0.104919          0.891225  \n",
       "3    -1.109568        -1.383932                    1.600564         -0.751564  \n",
       "4     0.231034         0.078911                    0.404048          0.054690  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Failure type\n",
       "0    7722\n",
       "2      85\n",
       "3      64\n",
       "4      62\n",
       "1      34\n",
       "6      18\n",
       "5      15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de los modelos de ML\n",
    "\n",
    "Los parámetros de los modelos se dieron con la experimentación obtenida de la notebook `models_testing.ipynb`. Se usa el parámetro `class_weight='balanced'` para balancear las clases. Lo que hace este parámetro es que a las clases se les asigna un peso inversamente proporcional a su frecuencia en los datos. Esto ayuda a que el modelo se sesgue lo menos posible hacia la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'C': 0.5,                   # Regularization strength; must be a positive float. Smaller values specify stronger regularization.\n",
    "    'solver': 'lbfgs',          # Solver to use for optimization. 'lbfgs' is suitable for multiclass problems.\n",
    "    'max_iter': 1500,           # Maximum number of iterations to converge.\n",
    "    'multi_class': 'multinomial',  # Strategy to handle multiclass classification.\n",
    "    'random_state': 95,          # Random state for reproducibility.\n",
    "    'class_weight': 'balanced'  # Weights associated with classes; 'balanced' automatically adjusts weights inversely proportional to class frequencies\n",
    "}\n",
    "\n",
    "rfc_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_leaf': 10,\n",
    "    'min_samples_split': 10,\n",
    "    'class_weight': 'balanced',\n",
    "    'max_features': 5,\n",
    "    # 'oob_score': True,\n",
    "    'random_state': 95,\n",
    "    'criterion': 'gini'\n",
    "}\n",
    "\n",
    "# Define the hyperparameters for SVC\n",
    "svc_params = {\n",
    "    'C': 8.0,   # 50                # Regularization parameter, controls the trade-off between achieving a low error on training data and minimizing the norm of the weights\n",
    "    'kernel': 'rbf',            # Specifies the kernel type to be used in the algorithm ('rbf' for non-linear decision boundaries)\n",
    "    'gamma': 'scale',           # Kernel coefficient; 'scale' uses 1 / (n_features * X.var()) as value\n",
    "    'decision_function_shape': 'ovr',  # One-vs-rest strategy for multiclass classification\n",
    "    'class_weight': 'balanced', # Adjusts weights inversely proportional to class frequencies\n",
    "    'random_state': 95          # Seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase `ModelWrapper` lo que hace es añadir una funcionalidad encima de los modelos de `sklearn` para generar rápidamente el uso de sobremuestre o SMOTE y para obtener rápidamente y prográmaticamente los reportes de clasificación y las matrices de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ModelWrapper instance for the LogisticRegression model\n",
    "lr_wrapper = models.ModelWrapper(\n",
    "    model_class=LogisticRegression,\n",
    "    params=lr_params,\n",
    "    name='logistic_regression'\n",
    ")\n",
    "\n",
    "# Create a ModelWrapper instance for the RandomForestClassifier model\n",
    "rfc_wrapper = models.ModelWrapper(\n",
    "    model_class=RandomForestClassifier,\n",
    "    params=rfc_params,\n",
    "    name='random_forest'\n",
    ")\n",
    "\n",
    "# Create a ModelWrapper instance for the SVC model\n",
    "svc_wrapper = models.ModelWrapper(\n",
    "    model_class=SVC,\n",
    "    params=svc_params,\n",
    "    name='svc'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722034596.220600  439320 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-26 16:56:36.221816: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Define the neural_network\n",
    "neural_network = tf_models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(7,)),  # 7 input features\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(7, activation='softmax')  # 7 classes for the output\n",
    "])\n",
    "\n",
    "# Compile the neural_network\n",
    "neural_network.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['recall', 'f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wrapper = models.NeuralNetworkWrapper(model=neural_network, name='neural_network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución de los experimentos\n",
    "\n",
    "Para esto se usa la clase `ExperimentAutomation` del módulo `mltools.results`. La habilidad de esta clase es que puede ejecutar los experimentos de manera automática y guardar los resultados en una instancia de `ExperimentResults`.\n",
    "\n",
    "Por cada tipo de clasificador se ejecutan los siguientes experimentos usando siempre los mismos parámetros por clasificador:\n",
    "1. Clasificación sin ningún tipo de muestre.\n",
    "2. Clasificación con sobremuestreo.\n",
    "3. Clasificación con submuestreo.\n",
    "3. Clasificación con SMOTE.\n",
    "\n",
    "Todos estos resultados son guardados en una instancia de `ExperimentResults` para su posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [lr_wrapper, rfc_wrapper, svc_wrapper, nn_wrapper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = results.ExperimentAutomation(models_list=models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression model fitted.\n",
      "Results recorded for logistic_regression with no sampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression_oversampling model fitted.\n",
      "Results recorded for logistic_regression_oversampling with oversampling.\n",
      "logistic_regression_undersampling model fitted.\n",
      "Results recorded for logistic_regression_undersampling with undersampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression_smote model fitted.\n",
      "Results recorded for logistic_regression_smote with smote.\n",
      "random_forest model fitted.\n",
      "Results recorded for random_forest with no sampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/carroyo/personal_python_projects/predictive-maintenance-milling/tmp/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest_oversampling model fitted.\n",
      "Results recorded for random_forest_oversampling with oversampling.\n",
      "random_forest_undersampling model fitted.\n",
      "Results recorded for random_forest_undersampling with undersampling.\n",
      "random_forest_smote model fitted.\n",
      "Results recorded for random_forest_smote with smote.\n",
      "svc model fitted.\n",
      "Results recorded for svc with no sampling.\n",
      "svc_oversampling model fitted.\n",
      "Results recorded for svc_oversampling with oversampling.\n",
      "svc_undersampling model fitted.\n",
      "Results recorded for svc_undersampling with undersampling.\n",
      "svc_smote model fitted.\n",
      "Results recorded for svc_smote with smote.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - f1_score: 0.1062 - loss: 1.9302 - recall: 0.0014 - val_f1_score: 0.1095 - val_loss: 1.7232 - val_recall: 0.0175\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.1223 - loss: 1.4624 - recall: 0.0540 - val_f1_score: 0.1392 - val_loss: 1.4795 - val_recall: 0.1787\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.1656 - loss: 1.1944 - recall: 0.2050 - val_f1_score: 0.1742 - val_loss: 1.3028 - val_recall: 0.3038\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - f1_score: 0.1858 - loss: 1.0386 - recall: 0.2833 - val_f1_score: 0.1938 - val_loss: 1.1884 - val_recall: 0.3606\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2016 - loss: 0.9418 - recall: 0.3311 - val_f1_score: 0.2070 - val_loss: 1.1071 - val_recall: 0.4119\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2115 - loss: 0.8688 - recall: 0.3637 - val_f1_score: 0.2126 - val_loss: 1.0785 - val_recall: 0.4313\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2232 - loss: 0.8169 - recall: 0.3848 - val_f1_score: 0.2205 - val_loss: 1.0281 - val_recall: 0.4644\n",
      "Epoch 8/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2318 - loss: 0.7717 - recall: 0.4026 - val_f1_score: 0.2241 - val_loss: 1.0205 - val_recall: 0.4712\n",
      "Epoch 9/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2396 - loss: 0.7340 - recall: 0.4270 - val_f1_score: 0.2340 - val_loss: 0.9709 - val_recall: 0.5031\n",
      "Epoch 10/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2416 - loss: 0.7055 - recall: 0.4407 - val_f1_score: 0.2374 - val_loss: 0.9588 - val_recall: 0.5138\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2525 - loss: 0.6801 - recall: 0.4561 - val_f1_score: 0.2295 - val_loss: 0.9473 - val_recall: 0.5225\n",
      "Epoch 12/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2514 - loss: 0.6540 - recall: 0.4702 - val_f1_score: 0.2352 - val_loss: 0.9269 - val_recall: 0.5394\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2601 - loss: 0.6292 - recall: 0.4818 - val_f1_score: 0.2403 - val_loss: 0.9036 - val_recall: 0.5587\n",
      "Epoch 14/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2665 - loss: 0.6065 - recall: 0.4978 - val_f1_score: 0.2507 - val_loss: 0.8867 - val_recall: 0.5731\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2703 - loss: 0.5872 - recall: 0.5133 - val_f1_score: 0.2536 - val_loss: 0.8738 - val_recall: 0.5831\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2774 - loss: 0.5675 - recall: 0.5317 - val_f1_score: 0.2444 - val_loss: 0.8734 - val_recall: 0.5894\n",
      "Epoch 17/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2803 - loss: 0.5506 - recall: 0.5422 - val_f1_score: 0.2597 - val_loss: 0.8261 - val_recall: 0.6094\n",
      "Epoch 18/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2865 - loss: 0.5344 - recall: 0.5533 - val_f1_score: 0.2588 - val_loss: 0.8237 - val_recall: 0.6169\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2937 - loss: 0.5202 - recall: 0.5699 - val_f1_score: 0.2615 - val_loss: 0.8102 - val_recall: 0.6269\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - f1_score: 0.2948 - loss: 0.5030 - recall: 0.5768 - val_f1_score: 0.2613 - val_loss: 0.7981 - val_recall: 0.6394\n",
      "neural_network model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Results recorded for neural_network with no sampling.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Resampling the training data using oversampling.\n",
      "Epoch 1/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.7764 - loss: 0.3032 - recall: 0.8777 - val_f1_score: 0.1429 - val_loss: 3.4886 - val_recall: 0.2456\n",
      "Epoch 2/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8174 - loss: 0.1948 - recall: 0.9436 - val_f1_score: 0.1429 - val_loss: 4.8006 - val_recall: 0.2874\n",
      "Epoch 3/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8276 - loss: 0.1391 - recall: 0.9661 - val_f1_score: 0.1429 - val_loss: 5.4448 - val_recall: 0.2874\n",
      "Epoch 4/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8343 - loss: 0.1070 - recall: 0.9732 - val_f1_score: 0.1429 - val_loss: 5.6723 - val_recall: 0.2874\n",
      "Epoch 5/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8379 - loss: 0.0886 - recall: 0.9778 - val_f1_score: 0.1429 - val_loss: 5.6731 - val_recall: 0.2874\n",
      "Epoch 6/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8404 - loss: 0.0775 - recall: 0.9807 - val_f1_score: 0.1429 - val_loss: 5.4407 - val_recall: 0.2874\n",
      "Epoch 7/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8424 - loss: 0.0697 - recall: 0.9829 - val_f1_score: 0.1429 - val_loss: 5.2344 - val_recall: 0.2874\n",
      "Epoch 8/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8630 - loss: 0.0636 - recall: 0.9843 - val_f1_score: 0.1429 - val_loss: 4.9887 - val_recall: 0.2874\n",
      "Epoch 9/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8637 - loss: 0.0585 - recall: 0.9854 - val_f1_score: 0.1579 - val_loss: 4.7019 - val_recall: 0.3271\n",
      "Epoch 10/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8647 - loss: 0.0541 - recall: 0.9863 - val_f1_score: 0.1579 - val_loss: 4.3787 - val_recall: 0.3271\n",
      "Epoch 11/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8725 - loss: 0.0505 - recall: 0.9875 - val_f1_score: 0.1579 - val_loss: 4.0527 - val_recall: 0.3271\n",
      "Epoch 12/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8731 - loss: 0.0476 - recall: 0.9881 - val_f1_score: 0.1579 - val_loss: 3.6999 - val_recall: 0.3271\n",
      "Epoch 13/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8927 - loss: 0.0447 - recall: 0.9889 - val_f1_score: 0.1712 - val_loss: 3.3710 - val_recall: 0.3659\n",
      "Epoch 14/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.8934 - loss: 0.0423 - recall: 0.9896 - val_f1_score: 0.1841 - val_loss: 3.0463 - val_recall: 0.3659\n",
      "Epoch 15/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9199 - loss: 0.0401 - recall: 0.9901 - val_f1_score: 0.1841 - val_loss: 2.7709 - val_recall: 0.4075\n",
      "Epoch 16/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9202 - loss: 0.0381 - recall: 0.9903 - val_f1_score: 0.1955 - val_loss: 2.4874 - val_recall: 0.4484\n",
      "Epoch 17/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9205 - loss: 0.0365 - recall: 0.9906 - val_f1_score: 0.2055 - val_loss: 2.3030 - val_recall: 0.4484\n",
      "Epoch 18/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9208 - loss: 0.0350 - recall: 0.9909 - val_f1_score: 0.2152 - val_loss: 2.1470 - val_recall: 0.4898\n",
      "Epoch 19/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9210 - loss: 0.0337 - recall: 0.9913 - val_f1_score: 0.2234 - val_loss: 2.0147 - val_recall: 0.5282\n",
      "Epoch 20/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9196 - loss: 0.0325 - recall: 0.9914 - val_f1_score: 0.2382 - val_loss: 1.8662 - val_recall: 0.6443\n",
      "neural_network_oversampling model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step\n",
      "Results recorded for neural_network_oversampling with oversampling.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Resampling the training data using undersampling.\n",
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - f1_score: 0.8336 - loss: 0.0953 - recall: 0.9647 - val_f1_score: 0.2500 - val_loss: 1.6336 - val_recall: 0.6667\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8454 - loss: 0.0602 - recall: 0.9823 - val_f1_score: 0.2500 - val_loss: 1.6339 - val_recall: 0.6667\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8454 - loss: 0.0323 - recall: 0.9823 - val_f1_score: 0.2500 - val_loss: 1.6368 - val_recall: 0.6667\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8571 - loss: 0.0205 - recall: 1.0000 - val_f1_score: 0.2500 - val_loss: 1.6335 - val_recall: 0.6667\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8571 - loss: 0.0160 - recall: 1.0000 - val_f1_score: 0.2500 - val_loss: 1.6302 - val_recall: 0.6667\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0113 - recall: 1.0000 - val_f1_score: 0.2422 - val_loss: 1.6278 - val_recall: 0.6667\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8571 - loss: 0.0077 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6255 - val_recall: 0.6190\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8571 - loss: 0.0061 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6230 - val_recall: 0.6190\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0059 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6209 - val_recall: 0.6190\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0061 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6196 - val_recall: 0.6190\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0061 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6193 - val_recall: 0.6190\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0057 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6196 - val_recall: 0.6190\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - f1_score: 0.8571 - loss: 0.0051 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6203 - val_recall: 0.6190\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0046 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6213 - val_recall: 0.6190\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0041 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6222 - val_recall: 0.6190\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - f1_score: 0.8571 - loss: 0.0038 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6230 - val_recall: 0.6190\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0036 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6236 - val_recall: 0.6190\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - f1_score: 0.8571 - loss: 0.0034 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6241 - val_recall: 0.6190\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0033 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6245 - val_recall: 0.6190\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - f1_score: 0.8571 - loss: 0.0032 - recall: 1.0000 - val_f1_score: 0.2338 - val_loss: 1.6248 - val_recall: 0.6190\n",
      "neural_network_undersampling model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n",
      "Results recorded for neural_network_undersampling with undersampling.\n",
      "Type of y_train: <class 'pandas.core.series.Series'>\n",
      "Shape of y_train: (8000,)\n",
      "Resampling the training data using smote.\n",
      "Epoch 1/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9294 - loss: 0.0914 - recall: 0.9733 - val_f1_score: 0.2439 - val_loss: 1.4223 - val_recall: 0.6808\n",
      "Epoch 2/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9392 - loss: 0.0575 - recall: 0.9831 - val_f1_score: 0.2475 - val_loss: 1.2975 - val_recall: 0.7008\n",
      "Epoch 3/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9427 - loss: 0.0525 - recall: 0.9847 - val_f1_score: 0.2473 - val_loss: 1.3205 - val_recall: 0.6990\n",
      "Epoch 4/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9395 - loss: 0.0501 - recall: 0.9859 - val_f1_score: 0.2492 - val_loss: 1.2089 - val_recall: 0.7106\n",
      "Epoch 5/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9401 - loss: 0.0483 - recall: 0.9865 - val_f1_score: 0.2488 - val_loss: 1.1974 - val_recall: 0.7074\n",
      "Epoch 6/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9408 - loss: 0.0464 - recall: 0.9871 - val_f1_score: 0.2496 - val_loss: 1.1604 - val_recall: 0.7122\n",
      "Epoch 7/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9438 - loss: 0.0450 - recall: 0.9878 - val_f1_score: 0.2503 - val_loss: 1.1186 - val_recall: 0.7167\n",
      "Epoch 8/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9420 - loss: 0.0438 - recall: 0.9882 - val_f1_score: 0.2520 - val_loss: 1.0670 - val_recall: 0.7272\n",
      "Epoch 9/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9449 - loss: 0.0427 - recall: 0.9884 - val_f1_score: 0.2552 - val_loss: 0.8598 - val_recall: 0.7500\n",
      "Epoch 10/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9448 - loss: 0.0418 - recall: 0.9883 - val_f1_score: 0.2565 - val_loss: 0.7977 - val_recall: 0.7586\n",
      "Epoch 11/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9453 - loss: 0.0409 - recall: 0.9887 - val_f1_score: 0.2576 - val_loss: 0.7521 - val_recall: 0.7662\n",
      "Epoch 12/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9455 - loss: 0.0402 - recall: 0.9888 - val_f1_score: 0.2576 - val_loss: 0.7632 - val_recall: 0.7663\n",
      "Epoch 13/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - f1_score: 0.9457 - loss: 0.0393 - recall: 0.9891 - val_f1_score: 0.2586 - val_loss: 0.7525 - val_recall: 0.7731\n",
      "Epoch 14/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9460 - loss: 0.0386 - recall: 0.9894 - val_f1_score: 0.2603 - val_loss: 0.6898 - val_recall: 0.7857\n",
      "Epoch 15/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9548 - loss: 0.0377 - recall: 0.9896 - val_f1_score: 0.2605 - val_loss: 0.7117 - val_recall: 0.7865\n",
      "Epoch 16/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9549 - loss: 0.0370 - recall: 0.9897 - val_f1_score: 0.2619 - val_loss: 0.6980 - val_recall: 0.7965\n",
      "Epoch 17/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9553 - loss: 0.0364 - recall: 0.9901 - val_f1_score: 0.2627 - val_loss: 0.6910 - val_recall: 0.8019\n",
      "Epoch 18/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - f1_score: 0.9556 - loss: 0.0359 - recall: 0.9905 - val_f1_score: 0.2624 - val_loss: 0.6869 - val_recall: 0.7997\n",
      "Epoch 19/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9556 - loss: 0.0352 - recall: 0.9905 - val_f1_score: 0.2619 - val_loss: 0.7304 - val_recall: 0.7960\n",
      "Epoch 20/20\n",
      "\u001b[1m1352/1352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - f1_score: 0.9559 - loss: 0.0347 - recall: 0.9908 - val_f1_score: 0.2609 - val_loss: 0.8439 - val_recall: 0.7886\n",
      "neural_network_smote model fitted.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step\n",
      "Results recorded for neural_network_smote with smote.\n"
     ]
    }
   ],
   "source": [
    "experiments.run_experiment(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados de los experimentos\n",
    "\n",
    "La variable `experiments` tiene como atributo `results` el cual es una instancia de `ExperimentResults`. A su vez, esta instancia tiene un atributo `results_df`, el cual contiene los reportes de clasificación dentro de un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_total = experiments.results.results_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checamos si hay valores nulos. La falta de valores nulos indica que todos los experimentos se ejecutaron correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0\n",
       "recall       0\n",
       "f1-score     0\n",
       "support      0\n",
       "model        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_total.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados para exhaustividad o recall\n",
    "\n",
    "Para nosotros, recall es la principal métrica a considerar. Si consideramos una clase de falla, recall vendría siendo la proporción de los casos predichos correctamente de esa clase con respecto a todos los casos reales de esa clase. Es decir, qué tanto cubre el modelo los casos reales de esa clase. Mientras un recall más alto, menos falsos negativos tenemos.\n",
    "\n",
    "Siempre observamos el promedio macro porque queremos que todas las clases sean consideradas con igual importancia. También podríamos dar una importancia mucho menor a la clase mayoritaria. Sin embargo, con el promedio macro podemos obtener la suficiente información para tomar decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.79</td>\n",
       "      <td>random_forest_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.78</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.77</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>random_forest_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>logistic_regression_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>logistic_regression_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.75</td>\n",
       "      <td>svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.72</td>\n",
       "      <td>svc_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.72</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.72</td>\n",
       "      <td>svc_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.69</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.68</td>\n",
       "      <td>random_forest_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.68</td>\n",
       "      <td>svc_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.67</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.67</td>\n",
       "      <td>logistic_regression_undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           recall                              model\n",
       "macro avg    0.79         random_forest_oversampling\n",
       "macro avg    0.78                     neural_network\n",
       "macro avg    0.77                      random_forest\n",
       "macro avg    0.76                random_forest_smote\n",
       "macro avg    0.76          logistic_regression_smote\n",
       "macro avg    0.76   logistic_regression_oversampling\n",
       "macro avg    0.76                logistic_regression\n",
       "macro avg    0.75                                svc\n",
       "macro avg    0.72                   svc_oversampling\n",
       "macro avg    0.72       neural_network_undersampling\n",
       "macro avg    0.72                          svc_smote\n",
       "macro avg    0.69               neural_network_smote\n",
       "macro avg    0.68        random_forest_undersampling\n",
       "macro avg    0.68                  svc_undersampling\n",
       "macro avg    0.67        neural_network_oversampling\n",
       "macro avg    0.67  logistic_regression_undersampling"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    results_total[results_total.index == 'macro avg']\\\n",
    "        .sort_values(by='recall', ascending=False)[['recall', 'model']].round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados para F1-score\n",
    "\n",
    "Nos fijamos en F1-score porque es una métrica que combina precisión y recall. Aunque lo más importante es tener un recall alto, mientras menos falsos positivos se tenga, mejor. Así, los modelos con recall alto y precisión altos son mejores. El F1-score nos da una idea de qué tan bien se comporta el modelo en general.\n",
    "\n",
    "Recordemos que la precisión mide la razón entre los casos predichos correctamente de una clase con respecto a todos los casos predichos de esa clase. Es decir, es la tasa de verdaderos positivos respecto a la predicción. La diferencia con recall es que recall mide la tasa de verdaderos positivos respecto a los casos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.66</td>\n",
       "      <td>random_forest_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.62</td>\n",
       "      <td>random_forest_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.61</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.59</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.57</td>\n",
       "      <td>svc_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.56</td>\n",
       "      <td>svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.56</td>\n",
       "      <td>svc_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.55</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.54</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.38</td>\n",
       "      <td>logistic_regression_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.35</td>\n",
       "      <td>logistic_regression_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.35</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.33</td>\n",
       "      <td>random_forest_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.31</td>\n",
       "      <td>svc_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.30</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.25</td>\n",
       "      <td>logistic_regression_undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1-score                              model\n",
       "macro avg      0.66         random_forest_oversampling\n",
       "macro avg      0.62                random_forest_smote\n",
       "macro avg      0.61                      random_forest\n",
       "macro avg      0.59               neural_network_smote\n",
       "macro avg      0.57                          svc_smote\n",
       "macro avg      0.56                                svc\n",
       "macro avg      0.56                   svc_oversampling\n",
       "macro avg      0.55       neural_network_undersampling\n",
       "macro avg      0.54        neural_network_oversampling\n",
       "macro avg      0.38          logistic_regression_smote\n",
       "macro avg      0.35   logistic_regression_oversampling\n",
       "macro avg      0.35                logistic_regression\n",
       "macro avg      0.33        random_forest_undersampling\n",
       "macro avg      0.31                  svc_undersampling\n",
       "macro avg      0.30                     neural_network\n",
       "macro avg      0.25  logistic_regression_undersampling"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    results_total[results_total.index == 'macro avg']\\\n",
    "        .sort_values(by='f1-score', ascending=False)[['f1-score', 'model']].round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados para la precisión\n",
    "\n",
    "Los falsos positivos son un inconveniente. Aún así, es más inconveniente tener falsos negativos. Por esta razón dejamos la precisión para lo último. Los modelos con alta precisión y recall son los mejores. Podemos ver que el modelo con estas características es el Random Forest con sobremuestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.62</td>\n",
       "      <td>random_forest_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.58</td>\n",
       "      <td>random_forest_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.57</td>\n",
       "      <td>neural_network_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.55</td>\n",
       "      <td>random_forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.54</td>\n",
       "      <td>neural_network_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.52</td>\n",
       "      <td>svc_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.50</td>\n",
       "      <td>svc_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.49</td>\n",
       "      <td>svc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.49</td>\n",
       "      <td>neural_network_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.37</td>\n",
       "      <td>random_forest_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.33</td>\n",
       "      <td>logistic_regression_smote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.31</td>\n",
       "      <td>logistic_regression_oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.30</td>\n",
       "      <td>logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.28</td>\n",
       "      <td>svc_undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.25</td>\n",
       "      <td>neural_network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.23</td>\n",
       "      <td>logistic_regression_undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision                              model\n",
       "macro avg       0.62         random_forest_oversampling\n",
       "macro avg       0.58                random_forest_smote\n",
       "macro avg       0.57               neural_network_smote\n",
       "macro avg       0.55                      random_forest\n",
       "macro avg       0.54        neural_network_oversampling\n",
       "macro avg       0.52                          svc_smote\n",
       "macro avg       0.50                   svc_oversampling\n",
       "macro avg       0.49                                svc\n",
       "macro avg       0.49       neural_network_undersampling\n",
       "macro avg       0.37        random_forest_undersampling\n",
       "macro avg       0.33          logistic_regression_smote\n",
       "macro avg       0.31   logistic_regression_oversampling\n",
       "macro avg       0.30                logistic_regression\n",
       "macro avg       0.28                  svc_undersampling\n",
       "macro avg       0.25                     neural_network\n",
       "macro avg       0.23  logistic_regression_undersampling"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    results_total[results_total.index == 'macro avg']\\\n",
    "        .sort_values(by='precision', ascending=False)[['precision', 'model']].round(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "1. Random Forest tiene el mejor performance en general. Sus métricas en general mejoran con la aplicación de sobremuestreo o SMOTE.\n",
    "2. Máquinas de soporte vectorial no mejora mucho con la aplicación de sobremuestreo o SMOTE.\n",
    "3. La aplicación de sobremuestreo o SMOTE mejoran el performance de los modelos en general.\n",
    "4. La aplicación de submuestreo daña el performance de los modelos en general para este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
